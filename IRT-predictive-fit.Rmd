---
title: "Replicate Ben's IRT paper"
author: "radhika"
date: "1/21/2021"
output: github_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}

#install.packages("dplyr")
library(tidyr)
library(dplyr)
library(stringr) 
library(ggplot2)
library(readr)
library(norm)
library(knitr)
library(styler)


#install.packages("psych")
library(psych)
library(mirt)


#install.packages("lmtest")
library(lmtest)
```

```{r}

### Kang & Cohen parameters
# 
# a1 <- c(1.1005, NA, 2.2093, NA, 1.4493, NA, 0.7514, NA, 1.5789, NA, 0.6425, NA, 1.6254, NA, 1.3415, NA, 0.918, NA, 1.8027, NA, 0.8159, NA, 0.9375, NA, 0.9126, NA, 1.9395, NA, 0.3746, NA, 0.673, NA, 0.4166, NA, 1.2093, NA, 0.9486, NA, 1.4916)
# b1 <- c("0.4078", NA, "0.5696", NA, "–1.0610", NA, "–0.2437", NA, "0.3206", NA, "–1.3762", NA, "–0.9800", NA, "–0.6881", NA, "–0.3526", NA, "0.2400", NA, "0.5917", NA, "1.8891", NA, "–0.2690", NA, "0.3673", NA, "–0.9681", NA, "–1.2601", NA, "0.5225", NA, "–1.3356", NA, "0.9515", NA, "0.9811")
# c1 <- c(0.2228, NA, 0.2332, NA, 0.2337, NA, 0.1445, NA, 0.2581, NA, 0.2712, NA, 0.1232, NA, 0.1954, NA, 0.2709, NA, 0.2984, NA, 0.0587, NA, 0.1405, NA, 0.2339, NA, 0.2387, NA, 0.3527, NA, 0.1206, NA, 0.1244, NA, 0.1167, NA, 0.2787, NA, 0.1923)
# a2 <- c(0.5659, NA, 0.6128, NA, 1.1037, NA, 1.9886, NA, 0.5691, NA, 1.0346, NA, 1.1384, NA, 3.3488, NA, 2.6306, NA, 0.6652, NA, 1.0342, NA, 1.0163, NA, 1.2945, NA, 1.6521, NA, 0.9696, NA, 1.2369, NA, 0.7812, NA, 0.7728, NA, 0.5441, NA, 1.4025)
# b2 <- c("–0.1257", NA, "–0.7826", NA, "0.0615", NA, "0.4244", NA, "–0.7350", NA, "0.9836", NA, "–1.2651", NA, "–0.2252", NA, "–0.6576", NA, "1.7007", NA, "1.0805", NA, "–2.0452", NA, "0.1627", NA, "0.0573", NA, "1.2171", NA, "2.1226", NA, "0.4228", NA, "–0.1656", NA, "–0.2055", NA, "1.2841")
# c2 <- c(0.3426, NA, 0.1925, NA, 0.2324, NA, 0.1396, NA, 0.2059, NA, 0.3124, NA, 0.1832, NA, 0.1811, NA, 0.2537, NA, 0.2184, NA, 0.2261, NA, 0.3464, NA, 0.1455, NA, 0.3861, NA, 0.1046, NA, 0.1656, NA, 0.2696, NA, 0.178, NA, 0.1961, NA, 0.2917)
# 
# # clean up
# a <- c(a1, a2)
# a <- a[!is.na(a)]
# b <- c(b1, b2)
# b <- as.numeric(stringr::str_replace(b, "–", "-"))
# b <- b[!is.na(b)]
# b <- -b
# c <- c(c1, c2)
# c <- c[!is.na(c)]
# 
# a1=a1[!is.na(a1)]
# 
# b1 <- as.numeric(stringr::str_replace(b1, "–", "-"))
# b1 <- b1[!is.na(b1)]
# b1 <- -b1
# 
# c1=c1[!is.na(c1)]

```


### Generate data - function

```{r}
fun_simulate_data= function(nitem, sample.size, model, a, b,c, ability) {

### Null

a_null<- matrix(rep( 1, len=nitem), ncol = 1)

#Simulate response data 
 	if (model == "1PL"){

 dat <- simdata(a = a_null, 
                d = -b, 
                N = sample.size, 
                itemtype = '2PL', 
                Theta = ability)
 	}
 
 if (model == "2PL"){

 dat <- simdata(a = a, 
                d = -b, 
                N = sample.size, 
                itemtype = '2PL', 
                Theta = ability)
 }
 
 if (model == "3PL"){

 dat <- simdata(a = a, 
                d = -b, 
                N = sample.size, 
                itemtype = '3PL', 
                guess = c, 
                Theta = ability)
 }

  return(dat)
  
 }

#Check if dataset is correctly generated

# model1PL <- mirt(data=dat, 1,itemtype='Rasch', SE=FALSE, verbose=FALSE)
# coef = as.data.frame(coef(model1PL, simplify=T)$items[,2]) %>%
#   tibble::rownames_to_column(., "Item no") %>%
#   mutate("b"= b) %>%
#   rename(b_est= "coef(model1PL, simplify = T)$items[, 2]")
# 
# plot(coef$b,coef$b_est)

# model3PL <- mirt(data=dat, 1, itemtype='3PL', SE=F, verbose=FALSE)
# coef = as.data.frame(coef(model3PL, simplify=T)$items[,2]) %>%
#   tibble::rownames_to_column(., "Item no") %>%
#   mutate("b"= b) %>%
#   rename(b_est= "coef(model3PL, simplify = T)$items[, 2]")
#  plot(coef$b,coef$b_est)


```


```{r}
##Function to generate test and train dataset
fun_split_data = function(nitem, sample.size, data) {


m0=matrix(rbinom(nitem*sample.size, 1, .9), ncol=nitem)

m0_na_train <- ifelse(m0==0,NA,m0)
# m0 has 10% of values randomly set to 0. These values are set to missing
m0_na_test <- ifelse(m0==0,1,NA)

# Train dataset
dat_mr_train= data * m0_na_train  # Train dataset - 10% values are set to NA
dat_mr_test= data * m0_na_test # Test dataset - 90% of values are set to NA, keep the 10% values dropped from train

return(list(dat_mr_train, dat_mr_test,m0_na_test))

}
```



```{r}
### Get estimated paramters
est <- function(mod) {
  co <- coef(mod)
  co <- co[-length(co)]#why do i do this?
  pars <- do.call("rbind", co)
  theta <- fscores(mod, method = "ML", full.scores = TRUE)  ##note: this is where the ability scoring happens. we'll talk about the details of this component next week.
  nc <- ncol(theta)
  if (nc == 1) 
    theta <- as.numeric(theta) else theta <- theta[, ncol(resp) + 1]
  list(theta = theta, pars_diff = pars[, 2], pars_discrim = pars[, 1], pars_guess=pars[,3])
}


### Get probability
get_p <- function(est) {
  n1 <- length(est$theta)
  n2 <- length(est$pars_diff)
  th <- matrix(est$theta, n1, n2, byrow = FALSE)
  b_est <- matrix(est$pars_diff, n1, n2, byrow = TRUE)
  a_est <- matrix(est$pars_discrim, n1, n2, byrow = TRUE)
  c_est <- matrix(est$pars_guess, n1, n2, byrow = TRUE)
  kern <- exp(a_est*(th + b_est))
  c_est + (1-c_est)*(kern/(1 + kern))
}

elplMR_MD <- function(p_model, p_true){
	p_model_correct <- log(p_model^p_true * (1 - p_model)^(1 - p_true))
	p_model_correct=ifelse(is.finite(p_model_correct),p_model_correct,0)
	sum(p_model_correct)
}

```


```{r}

### Predictive fit - Missing response

predict_fit_mr= function(nitem, sample.size, model, a,b,c,ability) {

#Simulate response data 

dat = fun_simulate_data(nitem, sample.size, model, a,b,c,ability)
dat_split = fun_split_data(nitem, sample.size, dat)

### break into test and train
dat_mr_train =  dat_split[[1]]
dat_mr_test = dat_split[[2]]
m0_na_test = dat_split[[3]]

#Estimate item parameters for train dataset (with missing data)
model1PL <- mirt(dat_mr_train, 1, itemtype='Rasch', SE=F, verbose=FALSE)
model2PL <- mirt(dat_mr_train, 1, itemtype='2PL', SE=F, verbose=FALSE)
model3PL <- mirt(dat_mr_train, 1, itemtype='3PL', SE=F, verbose=FALSE)


est_1PL_mr = est(model1PL)
est_2PL_mr = est(model2PL)
est_3PL_mr = est(model3PL)


# Predicted probabilities for missing cells
p_est_1PL <- get_p(est_1PL_mr) *m0_na_test
p_est_2PL <- get_p(est_2PL_mr) *m0_na_test
p_est_3PL <- get_p(est_3PL_mr) *m0_na_test

	
# Calculate log likelihood
results = rbind(c(model = "1PL", LL=round(elplMR_MD(p_est_1PL, dat_mr_test),3)),
                c(model = "2PL", LL=round(elplMR_MD(p_est_2PL, dat_mr_test),3)),
                c(model = "3PL", LL=round(elplMR_MD(p_est_3PL, dat_mr_test),3)))

return(results)
}
```


```{r}
#50 items, 1000 respondents
nitem=20
sample.size=500
iter=500

c1=0
c2=0
c3=0

ability <- as.matrix(rnorm(sample.size, mean = 0, sd = 1), ncol=1)

a <- as.matrix(rlnorm(nitem, meanlog = 0, sdlog = 1), ncol=1) #lognormal
b <- as.matrix(rnorm(nitem, mean = 0, sd = 1), ncol=1) #normal
c <- as.matrix(rbeta(nitem, shape1 = 5, shape2 = 17), ncol=1) #beta

for (i in 1:iter){
result1 = predict_fit_mr(nitem,sample.size, model = "3PL", a,b,c,ability )
max = which.max(result1[,2])
if(max==1) {c1=c1+1}
if(max==2) {c2=c2+1}
if(max==3) {c3=c3+1}

print(i)
print(c1)
print(c2)
print(c3)
print(result1)
print(min)

}

print("MR, DGM 3PL, 500 people")
print(c1)
print(c2)
print(c3)
```





